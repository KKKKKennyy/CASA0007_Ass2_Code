{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "House_Price = pd.read_csv('Data/HousePrice.csv')\n",
    "Scores = pd.read_csv('Data/Scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Columns = ['Local authority code', 'LSOA code', 'LSOA name', 'Year ending Mar 2019',\n",
    "                     'Year ending Jun 2019', 'Year ending Sep 2019', 'Year ending Dec 2019']\n",
    "\n",
    "House_Price_2019 = House_Price[Selected_Columns]\n",
    "\n",
    "House_Price_2019 = House_Price_2019.rename(columns={\n",
    "    'Local authority code': 'Local_Authority_Code',\n",
    "    'LSOA code': 'LSOA_Code',\n",
    "    'LSOA name': 'LSOA_Name',\n",
    "    'Year ending Mar 2019': 'Mar_2019',\n",
    "    'Year ending Jun 2019': 'Jun_2019',\n",
    "    'Year ending Sep 2019': 'Sep_2019',\n",
    "    'Year ending Dec 2019': 'Dec_2019'\n",
    "})\n",
    "\n",
    "House_Price_2019['Mar_2019'] = pd.to_numeric(House_Price_2019['Mar_2019'].str.replace(',', ''), errors='coerce')\n",
    "House_Price_2019['Jun_2019'] = pd.to_numeric(House_Price_2019['Jun_2019'].str.replace(',', ''), errors='coerce')\n",
    "House_Price_2019['Sep_2019'] = pd.to_numeric(House_Price_2019['Sep_2019'].str.replace(',', ''), errors='coerce')\n",
    "House_Price_2019['Dec_2019'] = pd.to_numeric(House_Price_2019['Dec_2019'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "House_Price_2019['Year_2019'] = House_Price_2019[['Mar_2019', 'Jun_2019', 'Sep_2019', 'Dec_2019']].mean(axis=1, skipna=False).fillna(0)\n",
    "\n",
    "House_Price_2019 = House_Price_2019[House_Price_2019['Year_2019']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores_Filtered = Scores[['LSOA code (2011)', 'Income Score (rate)', 'Education, Skills and Training Score', 'Crime Score', 'Barriers to Housing and Services Score', 'Living Environment Score']]\n",
    "\n",
    "Scores_Filtered = Scores_Filtered.rename(columns={\n",
    "    'LSOA code (2011)': 'LSOA_Code',\n",
    "    'Income Score (rate)': 'Income_Score',\n",
    "    'Education, Skills and Training Score': 'Education_Score',\n",
    "    'Barriers to Housing and Services Score': 'Barriers_Score',\n",
    "    'Crime Score': 'Crime_Score',\n",
    "    'Living Environment Score': 'Living_Score'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_df = pd.merge(House_Price_2019, Scores_Filtered, on='LSOA_Code')\n",
    "\n",
    "Merged_df_Filtered = Merged_df[['Year_2019', 'Income_Score', 'Education_Score', 'Crime_Score', 'Barriers_Score', 'Living_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_df_Filered_log = Merged_df_Filtered.copy()\n",
    "\n",
    "Merged_df_Filered_log['Year_2019'] = np.log(Merged_df_Filered_log['Year_2019'])\n",
    "\n",
    "Merged_df_Filered_log['Education_Score'] = Merged_df_Filered_log['Education_Score'] - Merged_df_Filered_log['Education_Score'].min() + 1\n",
    "Merged_df_Filered_log['Education_Score'] = np.log(Merged_df_Filered_log['Education_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model3_Data = Merged_df_Filered_log.copy()\n",
    "\n",
    "Model3_Data['Crose_With_Education_and_Income'] = Model3_Data['Income_Score'] * Model3_Data['Education_Score']\n",
    "Model3_Data['Crose_With_Living_and_Income'] = Model3_Data['Income_Score'] * Model3_Data['Living_Score']\n",
    "Model3_Data['Crose_With_Crime_and_Income'] = Model3_Data['Income_Score'] * Model3_Data['Crime_Score']\n",
    "Model3_Data['Crose_With_Barriers_and_Income'] = Model3_Data['Income_Score'] * Model3_Data['Barriers_Score']\n",
    "#Model3_Data['Income_Square'] = Model3_Data['Income_Score'] * Model3_Data['Income_Score']\n",
    "Model3_Data['Crose_With_Barriers_and_Living'] = Model3_Data['Living_Score'] * Model3_Data['Barriers_Score']\n",
    "Model3_Data['Crose_With_Barriers_and_Crime'] = Model3_Data['Crime_Score'] * Model3_Data['Barriers_Score']\n",
    "Model3_Data['Crose_With_Barriers_and_Education'] = Model3_Data['Education_Score'] * Model3_Data['Barriers_Score']\n",
    "Model3_Data['Crose_With_Living_and_Education'] = Model3_Data['Education_Score'] * Model3_Data['Living_Score']\n",
    "Model3_Data['Crose_With_Living_and_Crime'] = Model3_Data['Living_Score'] * Model3_Data['Crime_Score']\n",
    "\n",
    "Model3_Data['Crose_With_Education_and_Crime'] = Model3_Data['Education_Score'] * Model3_Data['Crime_Score']\n",
    "\n",
    "\n",
    "Model3_Data['Education_Square'] = Model3_Data['Education_Score'] * Model3_Data['Education_Score']\n",
    "Model3_Data['Crime_Square'] = Model3_Data['Crime_Score'] * Model3_Data['Crime_Score']\n",
    "Model3_Data['Barriers_Square'] = Model3_Data['Barriers_Score'] * Model3_Data['Barriers_Score']\n",
    "Model3_Data['Living_Square'] = Model3_Data['Living_Score'] * Model3_Data['Living_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Independent_Variables = Model3_Data[['Crose_With_Education_and_Income', 'Crose_With_Living_and_Income', 'Crose_With_Crime_and_Income', 'Crose_With_Barriers_and_Income',\n",
    "#                                      'Crose_With_Barriers_and_Living', 'Crose_With_Barriers_and_Crime', 'Crose_With_Barriers_and_Education',\n",
    "#                                      'Income_Score', 'Education_Score', 'Crime_Score', 'Barriers_Score', 'Living_Score']]\n",
    "\n",
    "# Independent_Variables = Model3_Data[['Crose_With_Living_and_Income', 'Crose_With_Crime_and_Income',\n",
    "#                                     'Crose_With_Barriers_and_Education',\n",
    "#                                       'Income_Score', 'Education_Score', 'Barriers_Score', 'Living_Score']]\n",
    "\n",
    "Independent_Variables = Model3_Data[['Crose_With_Education_and_Crime',\n",
    "                                  'Crose_With_Barriers_and_Education', 'Crose_With_Barriers_and_Living',\n",
    "                                  'Crose_With_Education_and_Income', 'Crose_With_Crime_and_Income',\n",
    "                                  'Income_Score', 'Education_Score', 'Crime_Score', 'Barriers_Score', 'Living_Score']]\n",
    "\n",
    "#Independent_Variables = Model3_Data[['Crime_Square', 'Education_Square', 'Crose_With_Barriers_and_Living', 'Crose_With_Education_and_Income', 'Income_Score', 'Barriers_Score', 'Living_Score']]\n",
    "\n",
    "#Independent_Variables = Model3_Data[['Crime_Square', 'Education_Square', 'Crose_With_Barriers_and_Living', 'Income_Score', 'Barriers_Score', 'Living_Score']]\n",
    "\n",
    "Dependent_Variable = Model3_Data[['Year_2019']]\n",
    "\n",
    "Independent_Variables_Train, Independent_Variables_Test, Dependent_Variable_Train, Dependent_Variable_Test = train_test_split(Independent_Variables, Dependent_Variable, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(Independent_Variables_Train)\n",
    "X_test_scaled = scaler.transform(Independent_Variables_Test)\n",
    "y_train_scales = scaler.fit_transform(Dependent_Variable_Train)\n",
    "y_test_scales = scaler.fit_transform(Dependent_Variable_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳超参数: {'alpha': 0.1, 'l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "elastic_net = ElasticNet()\n",
    "\n",
    "# 定义超参数空间\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "    'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# 创建GridSearchCV对象\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=3)\n",
    "\n",
    "# 在训练集上拟合模型并搜索最佳超参数\n",
    "grid_search.fit(X_train_scaled, y_train_scales)\n",
    "\n",
    "# 打印最佳超参数\n",
    "print(\"最佳超参数:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差 (MSE): 172.29956952039902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.17934041, -0.        , -0.        ,  0.03406411,\n",
       "       -0.08287617, -0.37616226,  0.        , -0.0366583 ,  0.18726305])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.1, random_state=42)\n",
    "elastic_net.fit(X_train_scaled, y_train_scales)\n",
    "y_pred = elastic_net.predict(X_test_scaled)\n",
    "mse = mean_squared_error(Dependent_Variable_Test.values, y_pred)\n",
    "print(\"均方误差 (MSE):\", mse)\n",
    "\n",
    "#print(y_pred.shape)\n",
    "\n",
    "#r_squared = elastic_net.score(y_pred, Dependent_Variable_Test.values)\n",
    "#r_squared = r2_score(Dependent_Variable_Test.values, y_pred)\n",
    "\n",
    "#print(\"决定系数 (R方):\", r_squared)\n",
    "elastic_net.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient 1: 0.0411899657364987, p-value: 1.240960043321746e-06\n",
      "Coefficient 2: -0.4293264861974172, p-value: 8.427316298391162e-169\n",
      "Coefficient 3: -0.03421204897934483, p-value: 1.1637871619154208e-20\n",
      "Coefficient 4: -0.0988068954218, p-value: 2.9550992659557285e-10\n",
      "Coefficient 5: -0.12379959446890754, p-value: 4.552801958892138e-06\n",
      "Coefficient 6: 0.21332246397815294, p-value: 8.841611631695323e-41\n"
     ]
    }
   ],
   "source": [
    "# 弹性网络模型的系数\n",
    "coef_elastic_net = elastic_net.coef_\n",
    "\n",
    "# 添加截距项\n",
    "X_with_intercept = sm.add_constant(Independent_Variables)\n",
    "\n",
    "# 使用statsmodels进行显著性测试\n",
    "model = sm.OLS(Dependent_Variable, X_with_intercept).fit()\n",
    "\n",
    "# 打印每个系数及其对应的p-value\n",
    "for i, coef in enumerate(coef_elastic_net):\n",
    "    p_val = model.pvalues[i + 1]  # 使用 model.pvalues 获取每个系数的p-value\n",
    "    print(f'Coefficient {i + 1}: {coef}, p-value: {p_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient 1: 0.12058949101201745, p-value: 0.0\n",
      "Coefficient 2: -0.05043953651472963, p-value: 0.0\n",
      "Coefficient 3: -0.10560077747302697, p-value: 0.2824783878663615\n",
      "Coefficient 4: 0.009740478282329004, p-value: 2.6978419498391304e-13\n",
      "Coefficient 5: -0.0502507210014269, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['Income_Score', 'Education_Score', 'Crime_Score', 'Barriers_Score', 'Living_Score', 'Year_2019']\n",
    "\n",
    "# 创建 MinMaxScaler 实例\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 在 Merged_df_Filtered 上拟合并转换数据\n",
    "Merged_df_Filtered_Normalised = Merged_df_Filtered.copy()\n",
    "Merged_df_Filtered_Normalised[columns_to_normalize] = scaler.fit_transform(Merged_df_Filtered[columns_to_normalize])\n",
    "\n",
    "\n",
    "Independent_Variables = Merged_df_Filtered_Normalised[['Income_Score', 'Education_Score', 'Crime_Score', 'Barriers_Score', 'Living_Score']]\n",
    "Dependent_Variable = Merged_df_Filtered_Normalised['Year_2019']\n",
    "\n",
    "# 添加截距项\n",
    "X_with_intercept = np.c_[np.ones(Independent_Variables.shape[0]), Independent_Variables]\n",
    "\n",
    "# 计算模型参数\n",
    "params = np.linalg.lstsq(X_with_intercept, Dependent_Variable, rcond=None)[0]\n",
    "n = len(Dependent_Variable)\n",
    "p = X_with_intercept.shape[1] - 1\n",
    "\n",
    "# 残差平方和\n",
    "residuals = Dependent_Variable - np.dot(X_with_intercept, params)\n",
    "sse = np.sum(residuals ** 2)\n",
    "\n",
    "# 估计的标准误差\n",
    "se = np.sqrt(sse / (n - p - 1))\n",
    "\n",
    "# 参数的标准误差\n",
    "params_se = np.sqrt(np.diag(np.linalg.inv(np.dot(X_with_intercept.T, X_with_intercept)) * se**2))\n",
    "\n",
    "# t统计量\n",
    "t_values = params / params_se\n",
    "\n",
    "# p-value\n",
    "p_values = 2 * (1 - stats.t.cdf(np.abs(t_values), n - p - 1))\n",
    "\n",
    "# 打印系数和对应的p-value\n",
    "for i, (coef, p_val) in enumerate(zip(params, p_values[1:])):\n",
    "    print(f'Coefficient {i + 1}: {coef}, p-value: {p_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
